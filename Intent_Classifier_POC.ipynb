{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk4MXO3zBeIF0YNaRLSKFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshHp/LLM/blob/main/Intent_Classifier_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LeLZBuUHcOI8"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import nltk\n",
        "import re\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load a pre-trained model for text classification (DistilBERT fine-tuned on NLI)\n",
        "MODEL_NAME = \"facebook/bart-large-mnli\"  # You can replace with a fine-tuned model\n",
        "classifier = pipeline(\"zero-shot-classification\", model=MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iJ5Jr-YcPZx",
        "outputId": "d9b7cd0f-9f45-48f1-b2ee-e60afc1226ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have the necessary NLTK tokenizer\n",
        "# Download punkt_tab\n",
        "nltk.download('punkt_tab')\n",
        "# Download the 'punkt' resource as well, if you haven't already.\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define a set of common greetings (expand as needed based on initial testing)\n",
        "GREETING_PATTERNS = re.compile(r\"^(hi|hello|hey|good morning|good evening|greetings|howdy|what's up|Good Eve)[,!\\. ]*\", re.IGNORECASE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUAht2EMfyw2",
        "outputId": "5a7e9b1d-3144-4821-d6e5-c9db106f445a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_greeting(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes greeting words if they appear at the beginning of the message.\n",
        "    \"\"\"\n",
        "    # Remove greetings appearing at the start of the message\n",
        "    cleaned_input = re.sub(GREETING_PATTERNS, \"\", user_input, count=1).strip()\n",
        "\n",
        "    return cleaned_input if cleaned_input else None  # Return None if no meaningful content remains\n",
        "\n",
        "def filter_greetings(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Processes user input: removes greetings and keeps only non-greeting content.\n",
        "    \"\"\"\n",
        "    # Step 1: Remove greeting if it appears at the beginning\n",
        "    cleaned_input = remove_greeting(user_input)\n",
        "\n",
        "    if not cleaned_input:\n",
        "        return None  # Entire message was a greeting\n",
        "\n",
        "    # Step 2: Perform sentence-wise classification\n",
        "    sentences = nltk.sent_tokenize(cleaned_input)\n",
        "    candidate_labels = [\"greeting\", \"non-greeting\"]\n",
        "\n",
        "    filtered_sentences = [\n",
        "        sentence for sentence in sentences if classifier(sentence, candidate_labels)[\"labels\"][0] == \"non-greeting\"\n",
        "    ]\n",
        "\n",
        "    return \" \".join(filtered_sentences) if filtered_sentences else None\n"
      ],
      "metadata": {
        "id": "L76_GK8vhLHR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "user_messages = [\n",
        "    \"Hi, How are you doing? I need more details on OT products, please suggest.\",\n",
        "    \"Good morning! Can you explain RAG pipelines?\",\n",
        "    \"Hey there!\",\n",
        "    \"Hello, what's the latest update on AI trends?\",\n",
        "    \"Hello!\",\n",
        "    \"How are you?\",\n",
        "    \"Tell me about the latest trends in AI.\",\n",
        "    \"Good morning!\",\n",
        "    \"What is RAG in LLMs?\",\n",
        "    \"Hello, tell me more about Service level agreement\",\n",
        "    \"Hi,I need some more details on OpenText products, please suggest.\",\n",
        "    \"Good Afternoon Sir, How are you?\",\n",
        "    \"Good Eve,tell me what kind of inputs should I add here ?\"\n",
        "]\n",
        "\n",
        "for msg in user_messages:\n",
        "    processed_msg = filter_greetings(msg)\n",
        "    if processed_msg:\n",
        "        print(f\"Sending to RAG: {processed_msg}\")\n",
        "    else:\n",
        "        print(f\"Ignored greeting: {msg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1FoDnbNhcWn",
        "outputId": "4d7894f9-f2f4-4693-8ab9-537bf5db4684"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending to RAG: I need more details on OT products, please suggest.\n",
            "Sending to RAG: Can you explain RAG pipelines?\n",
            "Ignored greeting: Hey there!\n",
            "Sending to RAG: what's the latest update on AI trends?\n",
            "Ignored greeting: Hello!\n",
            "Ignored greeting: How are you?\n",
            "Sending to RAG: Tell me about the latest trends in AI.\n",
            "Ignored greeting: Good morning!\n",
            "Sending to RAG: What is RAG in LLMs?\n",
            "Sending to RAG: tell me more about Service level agreement\n",
            "Sending to RAG: I need some more details on OpenText products, please suggest.\n",
            "Ignored greeting: Good Afternoon Sir, How are you?\n",
            "Sending to RAG: tell me what kind of inputs should I add here ?\n"
          ]
        }
      ]
    }
  ]
}